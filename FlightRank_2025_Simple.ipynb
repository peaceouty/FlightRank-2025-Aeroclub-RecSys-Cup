{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d4d5a0",
   "metadata": {},
   "source": [
    "# FlightRank 2025 - 精简版解决方案\n",
    "\n",
    "商务旅行者个性化航班推荐系统 - 直接输出submission文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877817d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境设置和库导入\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# TPU支持\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    HAS_TPU = True\n",
    "    print(f\"✅ TPU已连接，副本数: {strategy.num_replicas_in_sync}\")\n",
    "except:\n",
    "    HAS_TPU = False\n",
    "    strategy = None\n",
    "    print(\"⚠️ TPU不可用，使用CPU/GPU\")\n",
    "\n",
    "# 环境检测\n",
    "IN_KAGGLE = '/kaggle/' in os.getcwd()\n",
    "DATA_PATH = '/kaggle/input/aeroclub-recsys-2025/' if IN_KAGGLE else './'\n",
    "OUTPUT_PATH = '/kaggle/working/' if IN_KAGGLE else './'\n",
    "\n",
    "print(f\"🌍 运行环境: {'Kaggle' if IN_KAGGLE else '本地'}\")\n",
    "print(f\"📁 数据路径: {DATA_PATH}\")\n",
    "print(f\"📁 输出路径: {OUTPUT_PATH}\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "def load_data():\n",
    "    try:\n",
    "        train_df = pd.read_parquet(f'{DATA_PATH}train.parquet')\n",
    "        test_df = pd.read_parquet(f'{DATA_PATH}test.parquet')\n",
    "        sample_submission = pd.read_parquet(f'{DATA_PATH}sample_submission.parquet')\n",
    "        print(f\"训练数据: {train_df.shape}, 测试数据: {test_df.shape}\")\n",
    "        return train_df, test_df, sample_submission\n",
    "    except:\n",
    "        # 创建模拟数据\n",
    "        print(\"创建模拟数据\")\n",
    "        np.random.seed(42)\n",
    "        n_sessions = 50\n",
    "        data = []\n",
    "        flight_id = 1\n",
    "        \n",
    "        for session in range(1, n_sessions + 1):\n",
    "            n_flights = np.random.randint(5, 15)\n",
    "            selected_idx = np.random.randint(0, n_flights)\n",
    "            \n",
    "            for i in range(n_flights):\n",
    "                data.append({\n",
    "                    'Id': flight_id,\n",
    "                    'ranker_id': session,\n",
    "                    'totalPrice': np.random.uniform(200, 1500),\n",
    "                    'total_flight_duration': np.random.uniform(60, 600),\n",
    "                    'airline': np.random.choice(['DL', 'UA', 'AA']),\n",
    "                    'selected': 1 if i == selected_idx else 0\n",
    "                })\n",
    "                flight_id += 1\n",
    "        \n",
    "        train_df = pd.DataFrame(data[:int(len(data)*0.75)])\n",
    "        test_data = []\n",
    "        for session in range(n_sessions + 1, n_sessions + 21):\n",
    "            n_flights = np.random.randint(5, 15)\n",
    "            for i in range(n_flights):\n",
    "                test_data.append({\n",
    "                    'Id': flight_id,\n",
    "                    'ranker_id': session,\n",
    "                    'totalPrice': np.random.uniform(200, 1500),\n",
    "                    'total_flight_duration': np.random.uniform(60, 600),\n",
    "                    'airline': np.random.choice(['DL', 'UA', 'AA'])\n",
    "                })\n",
    "                flight_id += 1\n",
    "        \n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        sample_submission = pd.DataFrame({\n",
    "            'Id': test_df['Id'],\n",
    "            'rank': range(1, len(test_df) + 1)\n",
    "        })\n",
    "        \n",
    "        return train_df, test_df, sample_submission\n",
    "\n",
    "train_df, test_df, sample_submission = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "def create_features(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 类别编码\n",
    "    if 'airline' in df.columns:\n",
    "        df['airline_encoded'] = pd.Categorical(df['airline']).codes\n",
    "        df = df.drop('airline', axis=1)\n",
    "    \n",
    "    # 数值特征\n",
    "    numeric_cols = ['totalPrice', 'total_flight_duration']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            # 组内排名\n",
    "            df[f'{col}_rank'] = df.groupby('ranker_id')[col].rank().fillna(1).astype(int)\n",
    "            # 与最小值的差异\n",
    "            df[f'{col}_diff'] = (df[col] - df.groupby('ranker_id')[col].transform('min')).fillna(0)\n",
    "    \n",
    "    # 会话特征\n",
    "    df['session_size'] = df.groupby('ranker_id')['Id'].transform('count')\n",
    "    df['position'] = df.groupby('ranker_id').cumcount() + 1\n",
    "    \n",
    "    # 填充缺失值\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # 数据类型优化\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 处理数据\n",
    "train_features = create_features(train_df, is_train=True)\n",
    "test_features = create_features(test_df, is_train=False)\n",
    "\n",
    "print(f\"训练特征: {train_features.shape}, 测试特征: {test_features.shape}\")\n",
    "\n",
    "# 清理内存\n",
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPU神经网络模型（如果可用）\n",
    "def create_tpu_model(input_dim):\n",
    "    if not HAS_TPU:\n",
    "        return None\n",
    "        \n",
    "    def model_fn():\n",
    "        inputs = tf.keras.Input(shape=(input_dim,))\n",
    "        x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        return model\n",
    "    \n",
    "    with strategy.scope():\n",
    "        return model_fn()\n",
    "\n",
    "# 模型训练\n",
    "def train_model(train_features):\n",
    "    print(\"开始模型训练...\")\n",
    "    \n",
    "    # 准备数据\n",
    "    feature_cols = [col for col in train_features.columns if col not in ['Id', 'ranker_id', 'selected']]\n",
    "    X = train_features[feature_cols].fillna(0)\n",
    "    y = train_features['selected']\n",
    "    \n",
    "    print(f\"特征数量: {len(feature_cols)}, 样本数量: {len(X)}\")\n",
    "    print(f\"正样本比例: {y.mean():.4f}\")\n",
    "    \n",
    "    # 数据分割\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = -1\n",
    "    model_type = 'rf'\n",
    "    \n",
    "    # 首先尝试Random Forest（更稳定的基线）\n",
    "    print(\"训练Random Forest...\")\n",
    "    try:\n",
    "        rf_model = RandomForestRegressor(\n",
    "            n_estimators=100,  # 增加树的数量\n",
    "            max_depth=15,      # 增加深度\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=SEED, \n",
    "            n_jobs=1           # Kaggle环境下使用单线程更稳定\n",
    "        )\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_pred = rf_model.predict(X_val)\n",
    "        \n",
    "        # 改进评估方法：使用AUC-like评估\n",
    "        try:\n",
    "            rf_score = roc_auc_score(y_val, rf_pred)\n",
    "        except:\n",
    "            # 如果AUC计算失败，使用阈值方法\n",
    "            threshold = np.percentile(rf_pred, 80)  # 取80%分位数作为阈值\n",
    "            rf_score = np.mean((rf_pred > threshold) == y_val)\n",
    "        \n",
    "        best_model = rf_model\n",
    "        best_score = rf_score\n",
    "        model_type = 'rf'\n",
    "        print(f\"Random Forest得分: {rf_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Random Forest训练失败: {str(e)}\")\n",
    "        # 创建一个简单的基线模型\n",
    "        print(\"创建基线模型...\")\n",
    "        class SimpleModel:\n",
    "            def __init__(self):\n",
    "                self.mean_score = 0.5\n",
    "            def fit(self, X, y):\n",
    "                self.mean_score = y.mean()\n",
    "            def predict(self, X):\n",
    "                return np.full(len(X), self.mean_score)\n",
    "        \n",
    "        best_model = SimpleModel()\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_score = 0.5\n",
    "        model_type = 'baseline'\n",
    "    \n",
    "    # 如果有TPU，尝试深度学习模型\n",
    "    if HAS_TPU and best_score < 0.8:  # 只有当RF效果不好时才用TPU\n",
    "        try:\n",
    "            print(\"训练TPU神经网络...\")\n",
    "            tpu_model = create_tpu_model(X_train.shape[1])\n",
    "            \n",
    "            if tpu_model is not None:\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "                    X_train.values.astype(np.float32), \n",
    "                    y_train.values.astype(np.float32)\n",
    "                )).batch(128 * strategy.num_replicas_in_sync).prefetch(tf.data.AUTOTUNE)\n",
    "                \n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "                    X_val.values.astype(np.float32), \n",
    "                    y_val.values.astype(np.float32)\n",
    "                )).batch(128 * strategy.num_replicas_in_sync).prefetch(tf.data.AUTOTUNE)\n",
    "                \n",
    "                tpu_model.fit(train_dataset, validation_data=val_dataset, epochs=20, verbose=1)\n",
    "                \n",
    "                val_pred = tpu_model.predict(val_dataset)\n",
    "                try:\n",
    "                    tpu_score = roc_auc_score(y_val, val_pred.flatten())\n",
    "                except:\n",
    "                    tpu_score = np.mean(val_pred.flatten() > 0.5)\n",
    "                \n",
    "                if tpu_score > best_score:\n",
    "                    best_model = tpu_model\n",
    "                    best_score = tpu_score\n",
    "                    model_type = 'tpu'\n",
    "                    print(f\"TPU模型得分: {tpu_score:.4f}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"TPU训练失败: {str(e)}\")\n",
    "    \n",
    "    print(f\"最佳模型: {model_type}, 得分: {best_score:.4f}\")\n",
    "    \n",
    "    # 确保返回的模型不为None\n",
    "    if best_model is None:\n",
    "        print(\"所有模型都失败，创建随机基线...\")\n",
    "        class RandomModel:\n",
    "            def predict(self, X):\n",
    "                return np.random.random(len(X))\n",
    "        best_model = RandomModel()\n",
    "        model_type = 'random'\n",
    "    \n",
    "    return best_model, model_type\n",
    "\n",
    "model, model_type = train_model(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790adf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测和生成submission\n",
    "def predict_and_submit(model, model_type, test_features, sample_submission):\n",
    "    print(f\"开始预测，使用模型类型: {model_type}\")\n",
    "    \n",
    "    # 检查模型是否为None\n",
    "    if model is None:\n",
    "        print(\"❌ 模型为None，创建随机预测...\")\n",
    "        predictions = np.random.random(len(test_features))\n",
    "    else:\n",
    "        # 准备测试数据\n",
    "        feature_cols = [col for col in test_features.columns if col not in ['Id', 'ranker_id']]\n",
    "        X_test = test_features[feature_cols].fillna(0)\n",
    "        \n",
    "        print(f\"测试特征数量: {len(feature_cols)}, 测试样本数: {len(X_test)}\")\n",
    "        \n",
    "        # 预测\n",
    "        try:\n",
    "            if model_type == 'tpu' and HAS_TPU:\n",
    "                print(\"使用TPU模型预测...\")\n",
    "                test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "                    X_test.values.astype(np.float32)\n",
    "                ).batch(128 * strategy.num_replicas_in_sync).prefetch(tf.data.AUTOTUNE)\n",
    "                predictions = model.predict(test_dataset).flatten()\n",
    "            else:\n",
    "                print(\"使用传统模型预测...\")\n",
    "                predictions = model.predict(X_test)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"预测失败: {str(e)}\")\n",
    "            print(\"使用随机预测作为备选...\")\n",
    "            predictions = np.random.random(len(X_test))\n",
    "    \n",
    "    # 确保predictions是numpy数组\n",
    "    predictions = np.array(predictions).flatten()\n",
    "    \n",
    "    print(f\"预测值范围: {predictions.min():.4f} - {predictions.max():.4f}\")\n",
    "    \n",
    "    # 生成排名\n",
    "    result_df = test_features[['Id', 'ranker_id']].copy()\n",
    "    result_df['score'] = predictions\n",
    "    \n",
    "    # 按组排名（分数越高排名越前）\n",
    "    result_df['rank'] = result_df.groupby('ranker_id')['score'].rank(method='dense', ascending=False)\n",
    "    \n",
    "    # 创建提交文件\n",
    "    submission = result_df[['Id', 'rank']].copy()\n",
    "    submission['rank'] = submission['rank'].astype(int)\n",
    "    \n",
    "    # 验证排名的合理性\n",
    "    rank_stats = submission.groupby('rank').size()\n",
    "    print(f\"排名分布: {dict(rank_stats.head())}\")\n",
    "    \n",
    "    # 保存文件\n",
    "    submission_file = os.path.join(OUTPUT_PATH, 'submission.csv')\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    \n",
    "    print(f\"✅ 提交文件已保存: {submission_file}\")\n",
    "    print(f\"📊 提交文件形状: {submission.shape}\")\n",
    "    print(f\"🎯 处理了 {result_df['ranker_id'].nunique()} 个会话\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# 生成最终提交文件\n",
    "print(\"=\" * 50)\n",
    "print(\"开始生成提交文件...\")\n",
    "\n",
    "submission = predict_and_submit(model, model_type, test_features, sample_submission)\n",
    "\n",
    "# 显示前几行和统计信息\n",
    "print(\"\\n📋 前10行预测结果:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(f\"\\n📊 提交文件统计:\")\n",
    "print(f\"  - 总行数: {len(submission)}\")\n",
    "print(f\"  - Id范围: {submission['Id'].min()} - {submission['Id'].max()}\")\n",
    "print(f\"  - 排名范围: {submission['rank'].min()} - {submission['rank'].max()}\")\n",
    "\n",
    "print(\"\\n🎉 完成！submission.csv已生成并保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 模型问题诊断和修复\n",
    "print(\"🔍 诊断模型问题...\")\n",
    "\n",
    "# 检查当前模型状态\n",
    "print(f\"当前模型类型: {model_type}\")\n",
    "print(f\"模型对象: {type(model)}\")\n",
    "\n",
    "if model_type == 'baseline':\n",
    "    print(\"❌ 检测到使用了baseline模型，这会导致所有预测值相同\")\n",
    "    print(\"🔧 尝试重新训练更强的模型...\")\n",
    "    \n",
    "    # 重新准备数据\n",
    "    feature_cols = [col for col in train_features.columns if col not in ['Id', 'ranker_id', 'selected']]\n",
    "    X = train_features[feature_cols].fillna(0)\n",
    "    y = train_features['selected']\n",
    "    \n",
    "    print(f\"📊 数据检查:\")\n",
    "    print(f\"  - 特征数量: {len(feature_cols)}\")\n",
    "    print(f\"  - 样本数量: {len(X)}\")\n",
    "    print(f\"  - 正样本比例: {y.mean():.6f}\")\n",
    "    print(f\"  - 特征缺失值: {X.isnull().sum().sum()}\")\n",
    "    print(f\"  - 特征数值范围检查:\")\n",
    "    \n",
    "    for col in feature_cols[:5]:  # 检查前5个特征\n",
    "        print(f\"    {col}: {X[col].min():.2f} - {X[col].max():.2f}\")\n",
    "    \n",
    "    # 数据分割\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "    \n",
    "    print(f\"训练集: {X_train.shape}, 验证集: {X_val.shape}\")\n",
    "    \n",
    "    # 尝试多种模型\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_model_type = 'baseline'\n",
    "    \n",
    "    models_to_try = []\n",
    "    \n",
    "    # 1. 尝试简化的Random Forest\n",
    "    try:\n",
    "        print(\"\\n🌲 尝试简化Random Forest...\")\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        simple_rf = RandomForestRegressor(\n",
    "            n_estimators=20,    # 减少树数量\n",
    "            max_depth=8,        # 减少深度\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=SEED,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        simple_rf.fit(X_train, y_train)\n",
    "        rf_pred = simple_rf.predict(X_val)\n",
    "        \n",
    "        # 检查预测多样性\n",
    "        rf_std = np.std(rf_pred)\n",
    "        print(f\"  预测值标准差: {rf_std:.6f}\")\n",
    "        \n",
    "        if rf_std > 1e-6:  # 如果有足够的预测多样性\n",
    "            models_to_try.append(('simple_rf', simple_rf, rf_pred))\n",
    "            print(f\"  ✅ 简化RF成功，预测范围: {rf_pred.min():.6f} - {rf_pred.max():.6f}\")\n",
    "        else:\n",
    "            print(\"  ❌ 简化RF预测值缺乏多样性\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 简化RF失败: {str(e)}\")\n",
    "    \n",
    "    # 2. 尝试逻辑回归\n",
    "    try:\n",
    "        print(\"\\n📈 尝试逻辑回归...\")\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        lr_model = LogisticRegression(random_state=SEED, max_iter=1000, C=1.0)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        lr_pred = lr_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        lr_std = np.std(lr_pred)\n",
    "        print(f\"  预测值标准差: {lr_std:.6f}\")\n",
    "        \n",
    "        if lr_std > 1e-6:\n",
    "            models_to_try.append(('logistic', lr_model, lr_pred))\n",
    "            print(f\"  ✅ 逻辑回归成功，预测范围: {lr_pred.min():.6f} - {lr_pred.max():.6f}\")\n",
    "        else:\n",
    "            print(\"  ❌ 逻辑回归预测值缺乏多样性\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 逻辑回归失败: {str(e)}\")\n",
    "    \n",
    "    # 3. 尝试梯度提升\n",
    "    try:\n",
    "        print(\"\\n⚡ 尝试梯度提升...\")\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        gb_model = GradientBoostingRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            random_state=SEED\n",
    "        )\n",
    "        gb_model.fit(X_train, y_train)\n",
    "        gb_pred = gb_model.predict(X_val)\n",
    "        \n",
    "        gb_std = np.std(gb_pred)\n",
    "        print(f\"  预测值标准差: {gb_std:.6f}\")\n",
    "        \n",
    "        if gb_std > 1e-6:\n",
    "            models_to_try.append(('gradient_boosting', gb_model, gb_pred))\n",
    "            print(f\"  ✅ 梯度提升成功，预测范围: {gb_pred.min():.6f} - {gb_pred.max():.6f}\")\n",
    "        else:\n",
    "            print(\"  ❌ 梯度提升预测值缺乏多样性\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 梯度提升失败: {str(e)}\")\n",
    "    \n",
    "    # 4. 创建基于特征的简单模型\n",
    "    try:\n",
    "        print(\"\\n🎯 尝试基于特征的简单模型...\")\n",
    "        \n",
    "        # 使用关键特征创建简单得分函数\n",
    "        class FeatureBasedModel:\n",
    "            def __init__(self):\n",
    "                self.feature_weights = {}\n",
    "                \n",
    "            def fit(self, X, y):\n",
    "                # 计算每个特征与目标的相关性\n",
    "                for col in X.columns:\n",
    "                    try:\n",
    "                        corr = np.corrcoef(X[col], y)[0, 1]\n",
    "                        self.feature_weights[col] = corr if not np.isnan(corr) else 0\n",
    "                    except:\n",
    "                        self.feature_weights[col] = 0\n",
    "                        \n",
    "            def predict(self, X):\n",
    "                # 基于特征权重计算得分\n",
    "                scores = np.zeros(len(X))\n",
    "                for col, weight in self.feature_weights.items():\n",
    "                    if col in X.columns:\n",
    "                        # 标准化特征值\n",
    "                        col_values = X[col].values\n",
    "                        if np.std(col_values) > 0:\n",
    "                            normalized = (col_values - np.mean(col_values)) / np.std(col_values)\n",
    "                            scores += weight * normalized\n",
    "                \n",
    "                # 添加一些随机性以增加多样性\n",
    "                scores += np.random.normal(0, 0.1, len(scores))\n",
    "                return scores\n",
    "        \n",
    "        feature_model = FeatureBasedModel()\n",
    "        feature_model.fit(X_train, y_train)\n",
    "        feature_pred = feature_model.predict(X_val)\n",
    "        \n",
    "        feature_std = np.std(feature_pred)\n",
    "        print(f\"  预测值标准差: {feature_std:.6f}\")\n",
    "        \n",
    "        if feature_std > 1e-6:\n",
    "            models_to_try.append(('feature_based', feature_model, feature_pred))\n",
    "            print(f\"  ✅ 特征模型成功，预测范围: {feature_pred.min():.6f} - {feature_pred.max():.6f}\")\n",
    "        else:\n",
    "            print(\"  ❌ 特征模型预测值缺乏多样性\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ 特征模型失败: {str(e)}\")\n",
    "    \n",
    "    # 选择最佳模型\n",
    "    if models_to_try:\n",
    "        print(f\"\\n🏆 成功训练了 {len(models_to_try)} 个模型\")\n",
    "        \n",
    "        # 选择预测多样性最高的模型\n",
    "        best_std = 0\n",
    "        for model_name, model_obj, pred in models_to_try:\n",
    "            pred_std = np.std(pred)\n",
    "            print(f\"  {model_name}: 标准差 = {pred_std:.6f}\")\n",
    "            if pred_std > best_std:\n",
    "                best_std = pred_std\n",
    "                best_model = model_obj\n",
    "                best_model_type = model_name\n",
    "        \n",
    "        print(f\"🎯 选择模型: {best_model_type} (标准差: {best_std:.6f})\")\n",
    "        \n",
    "        # 更新全局模型变量\n",
    "        model = best_model\n",
    "        model_type = best_model_type\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ 所有模型都失败了，将使用改进的随机模型\")\n",
    "        \n",
    "        class ImprovedRandomModel:\n",
    "            def __init__(self):\n",
    "                pass\n",
    "                \n",
    "            def predict(self, X):\n",
    "                # 基于位置和简单特征的改进随机模型\n",
    "                scores = np.random.beta(2, 5, len(X))  # 偏向较小值的分布\n",
    "                \n",
    "                # 如果有位置特征，给前面位置更高权重\n",
    "                if 'position' in X.columns:\n",
    "                    position_boost = 1.0 / (X['position'].values + 1)\n",
    "                    scores *= (1 + position_boost)\n",
    "                \n",
    "                return scores\n",
    "        \n",
    "        model = ImprovedRandomModel()\n",
    "        model_type = 'improved_random'\n",
    "        print(\"✅ 使用改进随机模型\")\n",
    "\n",
    "else:\n",
    "    print(f\"✅ 当前模型 {model_type} 状态正常\")\n",
    "\n",
    "print(f\"\\n🎯 最终使用模型: {model_type}\")\n",
    "print(f\"模型对象类型: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04173c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 使用修复后的模型重新生成提交文件\n",
    "print(\"=\" * 60)\n",
    "print(\"🚀 使用修复后的模型重新生成提交文件...\")\n",
    "\n",
    "def predict_with_fixed_model(model, model_type, test_features):\n",
    "    \"\"\"使用修复后的模型进行预测\"\"\"\n",
    "    \n",
    "    print(f\"🔮 使用模型类型: {model_type}\")\n",
    "    \n",
    "    # 准备测试数据\n",
    "    feature_cols = [col for col in test_features.columns if col not in ['Id', 'ranker_id']]\n",
    "    X_test = test_features[feature_cols].fillna(0)\n",
    "    \n",
    "    print(f\"📊 测试数据: {len(X_test)} 样本, {len(feature_cols)} 特征\")\n",
    "    \n",
    "    # 进行预测\n",
    "    try:\n",
    "        if model_type == 'logistic':\n",
    "            # 逻辑回归需要用predict_proba\n",
    "            predictions = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            # 其他模型用predict\n",
    "            predictions = model.predict(X_test)\n",
    "            \n",
    "        predictions = np.array(predictions).flatten()\n",
    "        \n",
    "        print(f\"✅ 预测完成\")\n",
    "        print(f\"📈 预测值统计:\")\n",
    "        print(f\"  - 范围: {predictions.min():.6f} - {predictions.max():.6f}\")\n",
    "        print(f\"  - 均值: {predictions.mean():.6f}\")\n",
    "        print(f\"  - 标准差: {predictions.std():.6f}\")\n",
    "        \n",
    "        # 检查预测多样性\n",
    "        if predictions.std() < 1e-6:\n",
    "            print(\"⚠️ 预测值缺乏多样性，添加噪声...\")\n",
    "            predictions += np.random.normal(0, 0.001, len(predictions))\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 预测失败: {str(e)}\")\n",
    "        print(\"🎲 使用随机预测...\")\n",
    "        return np.random.beta(2, 5, len(X_test))\n",
    "\n",
    "# 进行预测\n",
    "predictions = predict_with_fixed_model(model, model_type, test_features)\n",
    "\n",
    "# 生成排名\n",
    "print(\"\\n🏆 生成排名...\")\n",
    "result_df = test_features[['Id', 'ranker_id']].copy()\n",
    "result_df['score'] = predictions\n",
    "\n",
    "# 按组排名（分数越高排名越前）\n",
    "result_df['rank'] = result_df.groupby('ranker_id')['score'].rank(method='dense', ascending=False)\n",
    "\n",
    "# 创建最终提交文件\n",
    "submission_fixed = result_df[['Id', 'rank']].copy()\n",
    "submission_fixed['rank'] = submission_fixed['rank'].astype(int)\n",
    "\n",
    "# 验证排名分布\n",
    "print(\"📊 排名分布验证:\")\n",
    "rank_distribution = submission_fixed['rank'].value_counts().sort_index().head(10)\n",
    "print(rank_distribution)\n",
    "\n",
    "# 检查每个会话的排名\n",
    "session_ranks = submission_fixed.groupby('ranker_id')['rank'].agg(['min', 'max', 'count']).head()\n",
    "print(\"\\n📋 前几个会话的排名检查:\")\n",
    "print(session_ranks)\n",
    "\n",
    "# 保存修复后的提交文件\n",
    "fixed_submission_file = os.path.join(OUTPUT_PATH, 'submission_fixed.csv')\n",
    "submission_fixed.to_csv(fixed_submission_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 修复后的提交文件已保存: {fixed_submission_file}\")\n",
    "print(f\"📊 文件统计:\")\n",
    "print(f\"  - 总行数: {len(submission_fixed)}\")\n",
    "print(f\"  - 会话数: {submission_fixed['ranker_id'].nunique()}\")\n",
    "print(f\"  - Id范围: {submission_fixed['Id'].min()} - {submission_fixed['Id'].max()}\")\n",
    "print(f\"  - 排名范围: {submission_fixed['rank'].min()} - {submission_fixed['rank'].max()}\")\n",
    "\n",
    "# 显示修复后的前几行\n",
    "print(\"\\n📋 修复后的前10行:\")\n",
    "print(submission_fixed.head(10))\n",
    "\n",
    "# 与原始提交文件对比\n",
    "if 'submission' in locals():\n",
    "    print(\"\\n🔄 与原始提交文件对比:\")\n",
    "    print(f\"原始排名范围: {submission['rank'].min()} - {submission['rank'].max()}\")\n",
    "    print(f\"修复排名范围: {submission_fixed['rank'].min()} - {submission_fixed['rank'].max()}\")\n",
    "    \n",
    "    # 检查是否有改进\n",
    "    original_unique_ranks = submission['rank'].nunique()\n",
    "    fixed_unique_ranks = submission_fixed['rank'].nunique()\n",
    "    \n",
    "    print(f\"原始唯一排名数: {original_unique_ranks}\")\n",
    "    print(f\"修复唯一排名数: {fixed_unique_ranks}\")\n",
    "    \n",
    "    if fixed_unique_ranks > original_unique_ranks:\n",
    "        print(\"✅ 排名多样性得到改善！\")\n",
    "    else:\n",
    "        print(\"⚠️ 排名多样性仍需改进\")\n",
    "\n",
    "print(\"\\n🎉 模型修复和重新预测完成！\")\n",
    "print(\"💡 请使用 submission_fixed.csv 作为最终提交文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6972459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 下载提交文件\n",
    "print(\"📥 准备下载提交文件...\")\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # 在Kaggle环境中，提供下载链接\n",
    "    from IPython.display import FileLink, display\n",
    "    \n",
    "    print(\"🌐 Kaggle环境 - 点击下载链接:\")\n",
    "    \n",
    "    # 显示修复后的文件下载链接\n",
    "    if os.path.exists('/kaggle/working/submission_fixed.csv'):\n",
    "        print(\"✅ 修复后的提交文件 (推荐使用):\")\n",
    "        display(FileLink('/kaggle/working/submission_fixed.csv'))\n",
    "    \n",
    "    # 显示原始文件下载链接\n",
    "    if os.path.exists('/kaggle/working/submission.csv'):\n",
    "        print(\"\\n📁 原始提交文件 (仅供对比):\")\n",
    "        display(FileLink('/kaggle/working/submission.csv'))\n",
    "    \n",
    "    # 列出所有可用文件\n",
    "    print(\"\\n📂 /kaggle/working/ 目录下的所有文件:\")\n",
    "    try:\n",
    "        import os\n",
    "        files = os.listdir('/kaggle/working/')\n",
    "        for file in files:\n",
    "            file_path = f'/kaggle/working/{file}'\n",
    "            file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "            print(f\"  📄 {file} ({file_size:.1f} MB)\")\n",
    "    except:\n",
    "        print(\"  无法列出文件\")\n",
    "        \n",
    "else:\n",
    "    # 本地环境\n",
    "    print(\"💻 本地环境 - 文件已保存在当前目录:\")\n",
    "    \n",
    "    if os.path.exists('submission_fixed.csv'):\n",
    "        print(\"✅ submission_fixed.csv (推荐使用)\")\n",
    "        print(f\"   文件大小: {os.path.getsize('submission_fixed.csv')/1024:.1f} KB\")\n",
    "    \n",
    "    if os.path.exists('submission.csv'):\n",
    "        print(\"📁 submission.csv (原始文件)\")\n",
    "        print(f\"   文件大小: {os.path.getsize('submission.csv')/1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n🎯 提交建议:\")\n",
    "print(\"1. 优先使用 'submission_fixed.csv' 文件\")\n",
    "print(\"2. 确认排名范围不是全为1\")\n",
    "print(\"3. 检查文件大小是否合理 (应该几十MB)\")\n",
    "print(\"4. 提交前可以查看前几行确认格式正确\")\n",
    "\n",
    "print(\"\\n🏁 算法项目完成！Good luck! 🍀\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
